{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "VGG_MEAN = [103.930,116.779,123.68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGGNet():\n",
    "    def __init__(self,data_dict):\n",
    "        self.data_dict = data_dict\n",
    "        \n",
    "    def get_conv_fliter(self,name):\n",
    "        return (tf.constant(self.data_dict[name][0]))\n",
    "    \n",
    "    def get_fc_weight(self,name):\n",
    "        return (tf.constant(self.data_dict[name][0]))\n",
    "    \n",
    "    def get_bias(self,name):\n",
    "        return (tf.constant(self.data_dict[name][1]))\n",
    "    \n",
    "    def conv_layer(self,x,name):\n",
    "        with tf.name_scope(name):\n",
    "            conv_w = self.get_conv_fliter(name)\n",
    "            conv_b = self.get_bias(name)\n",
    "            #输入x的shape = [bath_size,width,height,channel],stride是在每个维度的步长\n",
    "            h = tf.nn.conv2d(x,conv_w,strides=[1,1,1,1],padding='SAME')\n",
    "            h_add_b = tf.nn.bias_add(h,conv_b)\n",
    "            h_add_b_act = tf.nn.relu(h_add_b)\n",
    "        return h_add_b_act\n",
    "    \n",
    "    def pooling_layer(self,x,name):\n",
    "        with tf.name_scope(name):\n",
    "            return (tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\",name=name))\n",
    "    \n",
    "    def fc_layer(self,x,name,activation):\n",
    "        with tf.name_scope(name):\n",
    "            fc_w = self.get_fc_weight(name)\n",
    "            fc_b = self.get_bias(name)\n",
    "            h = tf.matmul(x,fc_w)\n",
    "            h_add_b = tf.bias_add(h,fc_b)\n",
    "            if activation is None:\n",
    "                return (h_add_b)\n",
    "            else:\n",
    "                return (activation(h_add_b))\n",
    "    \n",
    "    def flatten_layer(self,x,name):\n",
    "        with tf.name_scope(name):\n",
    "            x_shape = x.get_shape().as_list()\n",
    "            x_reshape = tf.reshape(x_shape,[x_shape[0],-1])\n",
    "            return x_reshape\n",
    "    \n",
    "    def build(self,x_rgb):\n",
    "        start_time = time.time()\n",
    "        print('building ...')\n",
    "        r,g,b = tf.split(x_rgb,num_or_size_splits=[1,1,1],axis=3)\n",
    "        x_rgb = tf.concat([b-VGG_MEAN[0],g-VGG_MEAN[1],r-VGG_MEAN[2]],axis=3)\n",
    "        \n",
    "        \n",
    "        self.conv1_1 = self.conv_layer(x_rgb, 'conv1_1')\n",
    "        self.conv1_2 = self.conv_layer(self.conv1_1, 'conv1_2')\n",
    "        self.pool1 = self.pooling_layer(self.conv1_2, 'pool1')\n",
    "\n",
    "        self.conv2_1 = self.conv_layer(self.pool1, 'conv2_1')\n",
    "        self.conv2_2 = self.conv_layer(self.conv2_1, 'conv2_2')\n",
    "        self.pool2 = self.pooling_layer(self.conv2_2, 'pool2')\n",
    "\n",
    "        self.conv3_1 = self.conv_layer(self.pool2, 'conv3_1')\n",
    "        self.conv3_2 = self.conv_layer(self.conv3_1, 'conv3_2')\n",
    "        self.conv3_3 = self.conv_layer(self.conv3_2, 'conv3_3')\n",
    "        self.pool3 = self.pooling_layer(self.conv3_3, 'pool3')\n",
    "\n",
    "        self.conv4_1 = self.conv_layer(self.pool3, 'conv4_1')\n",
    "        self.conv4_2 = self.conv_layer(self.conv4_1, 'conv4_2')\n",
    "        self.conv4_3 = self.conv_layer(self.conv4_2, 'conv4_3')\n",
    "        self.pool4 = self.pooling_layer(self.conv4_3, 'pool4')\n",
    "\n",
    "        self.conv5_1 = self.conv_layer(self.pool4, 'conv5_1')\n",
    "        self.conv5_2 = self.conv_layer(self.conv5_1, 'conv5_2')\n",
    "        self.conv5_3 = self.conv_layer(self.conv5_2, 'conv5_3')\n",
    "        self.pool5 = self.pooling_layer(self.conv5_3, 'pool5')\n",
    "        \n",
    "        print(\"the model is finished with %5d seconds\" % (time.time()-start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg16_npy_path = './vgg16.npy'\n",
    "content_img_path = './he.jpg'\n",
    "style_img_path = './start.jpg'\n",
    "num_steps = 1000\n",
    "learning_rate = 10\n",
    "lambda_c = 0.2\n",
    "lambda_s = 5000\n",
    "output_path = './the_sencond_run'\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e5f11bf2aa78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m127.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcontent_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_img_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e5f11bf2aa78>\u001b[0m in \u001b[0;36minitial_result\u001b[0;34m(shape, maen, stddev)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minitial_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minitial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstddev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "def initial_result(shape,mean,stddev):\n",
    "    initial = tf.truncated_normal(shape,mean = mean,stddev = stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def read_img(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    np_image = np.array(image)\n",
    "    np_imge_reshape = np.asarray([np_image])\n",
    "    return np_imge_reshape\n",
    "\n",
    "def gram_matrix(x):\n",
    "    b,w,h,c = x.get_shape().as_list()\n",
    "    x_reshape = x.reshape(b,w*h,c)\n",
    "    gram = tf.matmul(x_reshape,x_reshape,adjoint_a=True) / tf.constant(w*h*c,tf.float32)\n",
    "    return gram\n",
    "    \n",
    "\n",
    "\n",
    "result = initial_result([1,224,224,3],127.5,20)\n",
    "\n",
    "content_val = read_img(content_img_path)\n",
    "style_val = read_img(style_img_path)\n",
    "\n",
    "content = tf.placeholder(tf.float32,[1,224,224,3])\n",
    "style = tf.placeholder(tf.float32,[1,224,224,3])\n",
    "\n",
    "data_dict = np.load(vgg16_npy_path,allow_pickle=True,encoding='latin1').item()\n",
    "\n",
    "vgg_for_content = VGGNet(data_dict)\n",
    "vgg_for_style = VGGNet(data_dict)\n",
    "vgg_for_result = VGG(data_dict)\n",
    "\n",
    "vgg_for_content.build(content)\n",
    "vgg_for_style.build(style)\n",
    "vgg_for_result.build(result)\n",
    "\n",
    "feature_of_content = [vgg_for_content.conv1_2]\n",
    "feature_of_content_result = [vgg_for_result.conv1_2]\n",
    "\n",
    "feature_of_style = [vgg_for_style.conv4_3]\n",
    "gram_of_style =[gram_matrix(feature) for feature in feature_of_style]\n",
    "feature_of_style_result = [vgg_for_result.conv4_3]\n",
    "gram_of_style_result =[gram_matrix(feature) for feature in feature_of_style_result]\n",
    "\n",
    "content_loss = tf.zeros(1,tf.float32)\n",
    "\n",
    "for c,c_ in zip(feature_of_content,feature_of_content_result):\n",
    "    content_loss += tf.reduce_mean((c-c_)**2 ,axis=[1,2,3])\n",
    "    \n",
    "style_loss = tf.zeros(1,tf.float32)\n",
    "\n",
    "for s,s_ in zip(gram_of_style,gram_of_style_result):\n",
    "    style_loss += tf,reduce_mean((s-s_)**2,axis=[1,2])\n",
    "\n",
    "loss = lambda_c*content_loss + lambda_s *style_loss\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in range(num_steps):\n",
    "        loss_val,content_loss_val,style_loss_val,_ = \\\n",
    "                 sess.run([loss,content_loss,style_loss,train_op],\n",
    "                 feed_dict = {content:content_val , style:style_val})\n",
    "        print(\"step:%d,loss_val:%8.4f,content_loss:%8.4f,style_loss:%8.4f\",%(step+1,\n",
    "                                                                            loss_val[0],\n",
    "                                                                            content_loss_val[0],\n",
    "                                                                            style_loss_val[0]))\n",
    "        result_img_path = os.path.joim(output_path,'result_img_%d.jpg'%(step+1))\n",
    "        result_val = result.eval(sess)[0]\n",
    "        result_val = np.clip(result_val,0,255)\n",
    "        img_arr = np.asarray(result_val,np.uint8)\n",
    "        img = Image.fromarray(img_arr)\n",
    "        img_save(result_img_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
