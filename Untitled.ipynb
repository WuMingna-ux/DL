{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "mnist_path = './mnist.npz'\n",
    "def load_mnist():\n",
    "    \n",
    "    path = mnist_path #放置mnist.py的目录。注意斜杠\n",
    "    f = np.load(path)\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']\n",
    "    f.close()\n",
    "    return ((x_train, y_train), (x_test, y_test))\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()\n",
    "x_train = np.reshape(x_train,[-1,784])\n",
    "x_test = np.reshape(x_test,[-1,784])\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n",
      "(1000,)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class MINIST():\n",
    "    def __init__(self,x,y,num,need_shuffle):\n",
    "        sample_images = []\n",
    "        sample_lables = []\n",
    "        for i in range(num):\n",
    "            sample_images.append(x[i])\n",
    "            sample_lables.append(y[i])\n",
    "        sample_images = np.vstack(sample_images)\n",
    "        sample_lables = np.hstack(sample_lables)\n",
    "        self.sample_images = sample_images\n",
    "        self.sample_lables = sample_lables\n",
    "        print(self.sample_images.shape)\n",
    "        print(self.sample_lables.shape)\n",
    "        self.num_examples = self.sample_images.shape[0]\n",
    "        print(self.num_examples)\n",
    "        self.need_shuffle = need_shuffle\n",
    "        self.indicator = 0\n",
    "        if self.need_shuffle:\n",
    "            self.shuffle()\n",
    "    \n",
    "    def shuffle(self):\n",
    "        p = np.random.permutation(self.num_examples)\n",
    "        self.sample_images = self.sample_images[p]\n",
    "        self.sample_lables = self.sample_lables[p]\n",
    "    \n",
    "    def next_batch(self,batch_size):\n",
    "        end_indicator = self.indicator + batch_size\n",
    "        if end_indicator > self.num_examples:\n",
    "            if self.need_shuffle:\n",
    "                self.shuffle()\n",
    "                self.indicator = 0\n",
    "                end_indicator = self.indicator + batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        \n",
    "        if end_indicator > self.num_examples:\n",
    "            raise(\"the batch_size is too large\")\n",
    "        \n",
    "        batch_date = self.sample_images[self.indicator:end_indicator]\n",
    "        batch_labels = self.sample_lables[self.indicator:end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return (batch_date , batch_labels)\n",
    "       \n",
    "    \n",
    "train_data = MINIST(x_train,y_train,1000,True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step {i}, training accuracy {train_accuracy * 100:.2f}%\n",
      "step {i}, training accuracy {train_accuracy * 100:.2f}%\n",
      "step {i}, training accuracy {train_accuracy * 100:.2f}%\n",
      "step {i}, training accuracy {train_accuracy * 100:.2f}%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 读入数据。\n",
    "    with tf.name_scope(\"input\"):\n",
    "        # 训练图像的占位符。\n",
    "        x = tf.placeholder(tf.float32, [None, 784])\n",
    "        # 训练图像对应分类（标签）的占位符。\n",
    "        y = tf.placeholder(tf.int64, [None])\n",
    "        # 因为卷积要求输入的是4维数据，因此对形状进行转换。\n",
    "        # NHWC(默认)   NCHW\n",
    "        # N number样本的数量\n",
    "        # H height图像的高度\n",
    "        # W width图像的宽度v    \n",
    "        # C channel图像的通道数\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    # 卷积层1。\n",
    "    with tf.name_scope(\"conv_layer1\"):\n",
    "        # 定义权重。（w就是滑动窗口）\n",
    "        # 5, 5, 1, 32  =>  滑动窗口的高度，滑动窗口的宽度，输入通道数，输出通道数。\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1), name=\"w\")\n",
    "        # 定义偏置。\n",
    "        b = tf.Variable(tf.constant(0.0, shape=[32]), name=\"b\")\n",
    "        # 进行卷积计算。\n",
    "        # strides=[1, 1, 1, 1] 步幅。针对输入的NHWC定义的增量。\n",
    "        # padding： SAME 与VALID。SAME，只要滑动窗口不全移除输入区域就可以。\n",
    "        # VALID，滑动窗口必须完全在输入区域之内。\n",
    "        conv = tf.nn.bias_add(tf.nn.conv2d(x_image, w, strides=[1, 1, 1, 1], padding='SAME'), b, name=\"conv\")\n",
    "        # 使用激活函数进行激活。\n",
    "        activation = tf.nn.relu(conv)\n",
    "        # 池化操作。\n",
    "        # ksize：池化的窗口。\n",
    "        pool = tf.nn.max_pool(activation, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # 卷积层2。\n",
    "    with tf.name_scope(\"conv_layer2\"):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1), name=\"w\")\n",
    "        b = tf.Variable(tf.constant(0.0, shape=[64]), name=\"b\")\n",
    "        conv = tf.nn.bias_add(tf.nn.conv2d(pool, w, strides=[1, 1, 1, 1], padding='SAME'), b, name=\"conv\")\n",
    "        activation = tf.nn.relu(conv)\n",
    "        pool = tf.nn.max_pool(activation, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "    # 全连接层1。\n",
    "    with tf.name_scope(\"full_layer1\"):\n",
    "        # 7 * 7 * 64\n",
    "        # 原始图像是28 * 28，经过卷积与激励后，没有改变，经过2 * 2池化后，变成 14 * 14。\n",
    "        # 第一层卷积之后结果为14 * 14，经过第二层卷积与激励后，没有改变，经过2 * 2池化后，变成 7 * 7。\n",
    "        # 第二层卷积之后，我们图像的形状为  NHWC  =>  [N, 7, 7, 64]\n",
    "        # 4维变成2二维，将后面三维拉伸成为1维。  =》  [N, 7 * 7 * 64]\n",
    "        w = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1), name=\"w\")\n",
    "        b = tf.Variable(tf.constant(0.0, shape=[1024]), name=\"b\")\n",
    "        # 将第二层卷积之后的结果转换成二维结构。\n",
    "        pool = tf.reshape(pool, [-1, 7 * 7 * 64])\n",
    "        activation = tf.nn.relu(tf.matmul(pool, w) + b)\n",
    "        # 执行dropout（随机丢弃）\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        # 进行随机丢弃，keep_prob指定神经元的保留率。\n",
    "        drop = tf.nn.dropout(activation, keep_prob)\n",
    "        \n",
    "    # 全连接层2。\n",
    "    with tf.name_scope(\"full_layer2\"):\n",
    "        w = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1), name=\"w\")\n",
    "        b = tf.Variable(tf.constant(0.0, shape=[10]), name=\"b\")\n",
    "        logits = tf.matmul(drop, w) + b\n",
    "    \n",
    "    # 损失值与准确率计算层。\n",
    "    with tf.name_scope(\"compute\"):                   \n",
    "        # 计算损失值。\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "        tf.summary.scalar('loss',loss)\n",
    "        \n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "        # 计算准确率\n",
    "        predict  = tf.argmax(logits ,1)\n",
    "        correct = tf.equal(predict,y)\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\",accuracy)\n",
    "        merge = tf.summary.merge_all()\n",
    "\n",
    "LOG_DIR = '.'\n",
    "out_dir = os.path.join(LOG_DIR,'sun')\n",
    "if not os.path.exists():\n",
    "    mkdir(out_dir)\n",
    "\n",
    "        \n",
    "   \n",
    "\n",
    "    \n",
    "    batch_size = 32\n",
    "    with tf.Session() as sess:\n",
    "        # 对全局变量进行初始化。\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # 可以尝试更大的次数，可以将准确率提升到99%以上。\n",
    "        for i in range(1, 100):\n",
    "            train_writer = tf.summary.FileWriter('log/train',sess.graph)\n",
    "            test_writer = tf.summary.FileWriter('log/tets')\n",
    "            \n",
    "            batch_data , batch_labels = train_data.sample_images,train_data.sample_lables\n",
    "            # 每100步报告一次在验证集上的准确度\n",
    "            merge_op = [accuracy]\n",
    "            should_merge = ((i+1)% 10 ==0)\n",
    "            if should_merge:\n",
    "                merge_op.append(merge)\n",
    "            merge_op_result = sess.run(merge_op,\n",
    "                    feed_dict={x: batch_data, y: batch_labels, keep_prob: 1.0})\n",
    "                \n",
    "                print(\"step {i}, training accuracy {train_accuracy * 100:.2f}%\")\n",
    "            train_writer.add_summery(merge_op_result[-1],i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2 10]\n",
      " [ 4  5  6]\n",
      " [ 0  8  9]]\n",
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1,2,10],[4,5,6],[0,8,9]])\n",
    "print(arr)\n",
    "z = np.argmax(arr,0)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
