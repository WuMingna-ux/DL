{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wumingna\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5cd05469420a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../../datasets/image_caption_data/feature_extraction_inception_v3/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_folder' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np \n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pprint\n",
    "from tensorflow.compat.v1 import gfile\n",
    "from tensorflow.compat.v1 import logging\n",
    "#from tensorflow import gfile\n",
    "\n",
    "model_file = '../../datasets/image_caption_data/checkpoint_inception_v3/inception_v3_graph_def.pb'\n",
    "input_descroption_file = '../../datasets/image_caption_data/results_20130124.token'\n",
    "#input_img_dir = '../../datasets/image_caption_data/flicker30k_images/'\n",
    "output_folder = '../../datasets/image_caption_data/feature_extraction_inception_v3/'\n",
    "\n",
    "if not gfile.Exists(out_folder):\n",
    "    gfile.MakeDirs(out_folder)\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def parse_token_file(filename):\n",
    "    \"图片名：[[图片描述1],[图片描述2]……]\"\n",
    "    with gfile.GFile(filename, 'r' ) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    images_description = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        image_id, description = line.strip('\\r\\n').split('\\t')\n",
    "        image_name,_= image_id.split('#')\n",
    "        images_description.setdefault(image_name,[])\n",
    "        images_description[image_name].append(description)\n",
    "        \n",
    "    return images_description\n",
    "\n",
    "images_description = parse_token_file(input_descroption_file)\n",
    "all_img_names = list(images_description.keys()) # 获得图像名称\n",
    "logging.info(len(all_img_names))\n",
    "#pprint.pprint(all_img_names[0:10])\n",
    "pprint.pprint(images_description['2778832101.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pretrained_inception_v3(model_file):\n",
    "    '''导入已经训练好的计算图'''\n",
    "    with gfile.GFile(model_file,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def,name='graph_def')\n",
    "\n",
    "load_pretrained_inception_v3(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_batch = int(len(all_img_names) / batch_size)\n",
    "if len(all_img_names) / batch_size !=0:\n",
    "    num_batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "首先获得训练好的某层特征图\n",
    "然后根据图像名称读取每个batch_size里面的图像数据\n",
    "将图像数据传入模型中获得对应的图像特征\n",
    "将图像图像特征存储起来并写进文件中去\n",
    "'''\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    second_to_last_tensor = sess.graph.get_tensor_by_name(\"pool_3:0\")\n",
    "    for i in range(num_batch):\n",
    "        batch_img_names = all_img_names[i*batch_size: (i+1)*batch_size]\n",
    "        batch_features = []\n",
    "        for img_name in batch_img_names:\n",
    "            img_path = os.path.join(input_img_dir, img_name)\n",
    "\n",
    "            if not gfile.Exists(img_path):\n",
    "                raise Exception(\"%s doesn't exists\" % img_path)\n",
    "\n",
    "            logging.info('processing img %s' % img_name)\n",
    "\n",
    "            img_data = gfile.FastGFile(img_path, 'rb').read()\n",
    "            feature_vector = sess.run(second_to_last_tensor,\n",
    "                                      feed_dict={\n",
    "                                          'DecodeJpeg/contents:0': img_data\n",
    "                                      }\n",
    "                                      )\n",
    "\n",
    "            # 此刻的 feature_vector : Tensor(\"pool_3:0\", shape=(1, 1, 1, 2048), dtype=float32)\n",
    "            batch_features.append(feature_vector)\n",
    "\n",
    "        batch_features = np.vstack((batch_features))\n",
    "        output_filename = os.path.join(\n",
    "            output_folder,\n",
    "            'image_features-%d.pickle' % i\n",
    "        )\n",
    "        logging.info('writing to file %s' % output_filename)\n",
    "        with gfile.GFile(output_filename, 'w') as f:\n",
    "            pickle.dump((batch_img_names, batch_features), f)\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
