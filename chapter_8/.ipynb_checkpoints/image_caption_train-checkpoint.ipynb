{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#图像生成文字\n",
    "'''\n",
    "载入词表，构造两种映射关系\n",
    "word to id\n",
    "id to word\n",
    "\n",
    "将image_description的字典转换为{'图像名’：[[1,2,3,45467,123...],[24,56,...]]}\n",
    "\n",
    "载入图像特这帮\n",
    "构建batch，随机挑选出一个描述\n",
    "\n",
    "\n",
    "构建计算图\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wumingna\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import pprint\n",
    "import numpy as np \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.compat.v1 import gfile\n",
    "from tensorflow.compat.v1 import logging\n",
    "\n",
    "input_descroption_file = '../../datasets/image_caption_data/results_20130124.token'\n",
    "input_img_feature_dir = '../../datasets/image_caption_data/feature_extraction_inception_v3/'\n",
    "input_vocab_file = '../../datasets/image_caption_data/vocab.txt'\n",
    "output_dir = '../../datasets/image_caption_data/local_run'\n",
    "\n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class get_default_params():\n",
    "    def __init__(self,name):\n",
    "        self.name =name\n",
    "        self.num_vocab_threshold = 3\n",
    "        self.num_embedding_node =32\n",
    "        self.num_timesteps = 10\n",
    "        self.num_lstm_nodes =[64,64]\n",
    "        self.num_lstm_layer = 2\n",
    "        self.num_fc_nodes = 32\n",
    "        self.batch_size = 100\n",
    "        self.cell_type = 'lstm'\n",
    "        self.learning_rate = 0.1\n",
    "        self.keep_prob = 0.8\n",
    "        self.log_frequent = 500\n",
    "        self.save_frequent= 5000\n",
    "\n",
    "train_steps = 10000\n",
    "hps = get_default_params('hps1')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size is:10875\n",
      "[3838, 0, 1, 0]\n",
      "'the white A in'\n"
     ]
    }
   ],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self,filename,word_num_threshold):\n",
    "        self._word_to_id = {}\n",
    "        self._id_to_word = {}\n",
    "        self._unk = -1\n",
    "        self._eos = -1\n",
    "        self._word_num_threshold = word_num_threshold\n",
    "        self.read_file(filename)\n",
    "    \n",
    "    \n",
    "    def read_file(self,filename):\n",
    "        with gfile.GFile(filename,'r') as f:\n",
    "            lines =f.readlines()\n",
    "        for line in lines:\n",
    "            word,frequent = line.strip('\\r\\n').split('\\t')\n",
    "            frequent = int(frequent)\n",
    "            if frequent < self._word_num_threshold:\n",
    "                continue\n",
    "            idx = len(self._id_to_word)\n",
    "            if word == '<UNK>':\n",
    "                self._unk = idx\n",
    "            elif word =='.':\n",
    "                self._eos = idx\n",
    "            if idx in self._id_to_word or word in self._word_to_id:\n",
    "                raise Exception('duplicate words in vocab file')\n",
    "            self._word_to_id[word] = idx\n",
    "            self._id_to_word[idx] = word \n",
    "        \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return self._unk\n",
    "        \n",
    "    @property\n",
    "    def eos(self):\n",
    "        return self._eos\n",
    "        \n",
    "    def word_to_id(self,word):\n",
    "        return self._word_to_id.get(word,self.unk)\n",
    "        \n",
    "    def id_to_word(self,id):\n",
    "        return self._id_to_word.get(id,'<UNK>')\n",
    "        \n",
    "    def size(self):\n",
    "        return len(self._word_to_id)\n",
    "\n",
    "    def encode(self,sentence):\n",
    "        words_id = [self.word_to_id(word) for word in sentence.split(' ')]\n",
    "        return words_id\n",
    "\n",
    "    def decode(self,sentence_id):\n",
    "        id_words = [self.id_to_word(word_id) for word_id in sentence_id]  \n",
    "        return ' '.join(id_words)\n",
    "\n",
    "\n",
    "vocab = Vocab(input_vocab_file,hps.num_vocab_threshold)\n",
    "vocab_size = vocab.size()\n",
    "logging.info('vocab_size is:%d' %vocab_size)\n",
    "pprint.pprint(vocab.encode('i hava a dream'))\n",
    "pprint.pprint(vocab.decode([5,20,3,4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_token_file(token_file):\n",
    "    img_name_to_token = {}\n",
    "    with gfile.GFile(token_file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        image_id,description = line.strip('\\r\\n').split('\\t')\n",
    "        image_name,_ = image_id.split('#')\n",
    "        img_name_to_token.setdefault(image_name,[])\n",
    "        img_name_to_token[image_name].append(description)\n",
    "    return img_name_to_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_token_to_id(img_name_to_token,vocab):\n",
    "    img_name_to_token_id = {}\n",
    "    for image_name in img_name_to_token:\n",
    "        img_name_to_token_id.setdefault(image_name,[])\n",
    "        descriptions = img_name_to_token[image_name]\n",
    "        for description in descriptions:\n",
    "            ids = vocab.encode(description)\n",
    "            img_name_to_token_id[image_name].append(ids)\n",
    "    return img_name_to_token_id\n",
    "\n",
    "img_name_to_token = parse_token_file(input_descroption_file)\n",
    "img_name_to_token_id = convert_token_to_id(img_name_to_token,vocab)\n",
    "#logging.info(len(img_name_to_token))\n",
    "#pprint.pprint(img_name_to_token['2778832101.jpg'])\n",
    "#logging.info(len(img_name_to_token_id))\n",
    "#pprint.pprint(img_name_to_token_id['2778832101.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31783, 2048)\n",
      "(31783,)\n",
      "INFO:tensorflow:dim:2048\n",
      "INFO:tensorflow:data_size:31783\n"
     ]
    }
   ],
   "source": [
    "class ImageCaptionData(object):\n",
    "    '''\n",
    "    数据供应\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 img_name_to_token_ids,\n",
    "                 img_feature_dir,\n",
    "                 num_timesteps,\n",
    "                 vocab,\n",
    "                 deterministic=False):\n",
    "        '''\n",
    "\n",
    "        :param img_name_to_token_ids: 图像到描述字典\n",
    "        :param img_feature_dir: 图像特征 保存文件目录\n",
    "        :param num_timesteps: 时间步的数量\n",
    "        :param vocab: 词表\n",
    "        :param deterministic: 是否打乱\n",
    "        '''\n",
    "        self._vocab = vocab\n",
    "        self._all_img_feature_filepaths = [] # 拼接出　图像特征文件的　路径\n",
    "        for filename in gfile.ListDirectory(img_feature_dir):\n",
    "            self._all_img_feature_filepaths.append(os.path.join(img_feature_dir, filename))\n",
    "\n",
    "        self._img_name_to_token_ids = img_name_to_token_ids\n",
    "        self._num_timesteps = num_timesteps\n",
    "        self._indicator = 0 # batch_size 的 起始点\n",
    "        self._deterministic = deterministic\n",
    "        self._img_feature_filenames = [] # 保存所有图像特征的路径\n",
    "        self._img_feature_data = [] # 保存 所有 图像特征\n",
    "        self._load_img_feature_pickle()\n",
    "        if not self._deterministic:\n",
    "            self._random_shuffle()\n",
    "\n",
    "    def _load_img_feature_pickle(self):\n",
    "        '''\n",
    "        从 文件 从 读取 图像 特征\n",
    "        :return:\n",
    "        '''\n",
    "        for filepath in self._all_img_feature_filepaths:\n",
    "            with gfile.GFile(filepath, 'rb') as f:\n",
    "                filenames, features = pickle.load(f, encoding='iso-8859-1')\n",
    "                self._img_feature_filenames += filenames # 将列表拼接到一起\n",
    "                self._img_feature_data.append(features) # 将 特征 保存到一起\n",
    "        # 如 原来矩阵是 [#(1000, 1, 1, 2048), #(1000, 1, 1, 2048)] 合并之后为 (2000, 1, 1, 2048)\n",
    "        self._img_feature_data = np.vstack(self._img_feature_data)\n",
    "        origin_shape = self._img_feature_data.shape\n",
    "        # 此刻 origin_shape 的 shape：(31783, 1, 1, 2048)\n",
    "        self._img_feature_data = np.reshape( # 将其中的 两维度 去掉\n",
    "            self._img_feature_data, (origin_shape[0], origin_shape[3]))\n",
    "        self._img_feature_filenames = np.asarray(self._img_feature_filenames)\n",
    "        print(self._img_feature_data.shape) # (31783, 2048)\n",
    "        print(self._img_feature_filenames.shape) # (31783,)\n",
    "        if not self._deterministic:\n",
    "            self._random_shuffle()\n",
    "\n",
    "    def size(self):\n",
    "        # 图像文件的个数\n",
    "        return len(self._img_feature_filenames)\n",
    "\n",
    "    def img_feature_size(self):\n",
    "        # 获得图像特征的维度\n",
    "        return self._img_feature_data.shape[1]\n",
    "\n",
    "    def _random_shuffle(self):\n",
    "        p = np.random.permutation(self.size())\n",
    "        self._img_feature_filenames = self._img_feature_filenames[p]\n",
    "        self._img_feature_data = self._img_feature_data[p]\n",
    "\n",
    "    def _img_desc(self, filenames):\n",
    "        '''\n",
    "        从多条语句中，随机获得一条描述\n",
    "        :param filenames:\n",
    "        :return:\n",
    "        '''\n",
    "        batch_sentence_ids = []\n",
    "        batch_weights = []# 为最后 去掉无用的梯度做准备\n",
    "        for filename in filenames:\n",
    "            token_ids_set = self._img_name_to_token_ids[filename]\n",
    "            chosen_token_ids = random.choice(token_ids_set) # 随机选取一个\n",
    "            #chosen_token_ids = token_ids_set[0]\n",
    "            chosen_token_length = len(chosen_token_ids)\n",
    "\n",
    "            weight = [1 for i in range(chosen_token_length)]\n",
    "            if chosen_token_length >= self._num_timesteps:\n",
    "                chosen_token_ids = chosen_token_ids[0:self._num_timesteps]\n",
    "                weight = weight[0:self._num_timesteps]\n",
    "            else:# 否则 需要补零\n",
    "                # 计算需要补零的个数\n",
    "                remaining_length = self._num_timesteps - chosen_token_length\n",
    "                chosen_token_ids += [self._vocab.eos for i in range(remaining_length)]\n",
    "                weight += [0 for i in range(remaining_length)]\n",
    "            batch_sentence_ids.append(chosen_token_ids)\n",
    "            batch_weights.append(weight)\n",
    "        batch_sentence_ids = np.asarray(batch_sentence_ids)\n",
    "        batch_weights = np.asarray(batch_weights)\n",
    "        # 此刻返回的是 batch 句子描述， 和 weights\n",
    "        return batch_sentence_ids, batch_weights\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        '''\n",
    "                返回 batch_size 个数据\n",
    "                流程如下：\n",
    "                1. 得到 图像名称\n",
    "                2. 得到 图像特征\n",
    "                3. 得到 图像描述信息\n",
    "                :param batch_size:\n",
    "                :return:\n",
    "                '''\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self.size():\n",
    "            if not self._deterministic:\n",
    "                self._random_shuffle()\n",
    "            self._indicator = 0\n",
    "            end_indicator = self._indicator + batch_size\n",
    "        assert end_indicator <= self.size()\n",
    "\n",
    "        batch_img_features = self._img_feature_data[self._indicator: end_indicator]\n",
    "        batch_img_names = self._img_feature_filenames[self._indicator: end_indicator]\n",
    "\n",
    "        # batch_sentence_ids 是 图像描述 的id形式，\n",
    "        # batch_weights 句子权重，sentence_ids:[100, 101, 102, 0, 0, 0]--->[1, 1, 1, 0, 0, 0]\n",
    "        #   相当于是一个mask，和sentence_ids相乘，计算损失函数的时候，不去计算他们的损失\n",
    "        batch_sentence_ids, batch_weights = self._img_desc(batch_img_names)\n",
    "\n",
    "        self._indicator = end_indicator\n",
    "        return batch_img_features, batch_sentence_ids, batch_weights, batch_img_names\n",
    "caption_data = ImageCaptionData(img_name_to_token_id, input_img_feature_dir, hps.num_timesteps, vocab)\n",
    "img_feature_dim = caption_data.img_feature_size()\n",
    "logging.info('dim:%d' %img_feature_dim)\n",
    "logging.info('data_size:%d' %caption_data.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def creat_rnn_cell(hidden_dim,cell_type):\n",
    "    if cell_type == 'lstm':\n",
    "        return tf.nn.rnn_cell.BasicLSTMCell(hidden_dim,state_is_tuple=true)\n",
    "    if cell_type == 'gru':\n",
    "        return tf.nn.rnn_cell.GRUCell(hidden_dim)\n",
    "\n",
    "def drop_out(cell,keep_drop):\n",
    "    return tf.nn.rnn_cell.DropoutWrapper(cell,keep_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creat_train_model(hps,vocab_size,img_feature_dim):\n",
    "    num_timesteps = hps.num_timesteps\n",
    "    batch_size = hps.batch_size\n",
    "    \n",
    "    image_feature = tf.placeholder(tf.float32,[batch_size,img_feature_dim])\n",
    "    sentence = tf.placeholder(tf.int64,[batch_size,num_timesteps])\n",
    "    mask = tf.placeholder(tf.float32,[batch_size,num_timesteps])\n",
    "    keep_prob = tf.placeholder(tf.float32,name = 'keep_prob')\n",
    "    \n",
    "    global_step = tf.Variable(tf.zeros([],tf.int64),name='global_step',trainable=False)\n",
    "    \n",
    "    init_embedding = tf.random_uniform_initializer(-1.0,1.0)\n",
    "    with tf.variable_scope('embedding',initializer=init_embedding):\n",
    "        matrix_embedding = tf.get_variable('embedding',[vocab_size,hps.num_embedding_node],tf.float32)\n",
    "        #embed_look的大小是：batch_size,num_timestep-1,num_embedding_node\n",
    "        embed_look = tf.nn.embedding_lookup(matrix_embedding,sentence[:,1:num_timesteps])\n",
    "        \n",
    "        init_image_feature = tf.uniform_unit_scaling_initializer(factor=1.0)\n",
    "        with tf.variable_scope('init_image_feature',initializer=init_image_feature):\n",
    "            embed_img = tf.layers.dense(image_feature,hps.num_embedding_node)\n",
    "            embed_img = tf.expand_dims(embed_img,1)\n",
    "            embed_input = tf.concat([embed_img,embed_look],axis=1)\n",
    "            \n",
    "            \n",
    "    scale = 1.0 / math.sqrt(hps.num_embedding_nodes + hps.num_lstm_nodes[-1]) / 3.0\n",
    "    lstm_init = tf.random_uniform_initializer(-scale, scale)\n",
    "    with tf.variable_scope('lstm',initializer=lstm_init):\n",
    "        cells = []\n",
    "        for i in range(hps.num_lstm_layer):\n",
    "            cell = creat_rnn_cell(hps.num_lstm_nodes[i],hps.cell_type)\n",
    "            cell = drop_out(cell,keep_prob)\n",
    "            cells.append(cell)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "        \n",
    "        init_state = cell.zero_state(hps.batch_size,tf.float32)\n",
    "        rnn_output = tf.nn.dynamic_rnn(cell,embed_input,initial_state=init_state)\n",
    "        \n",
    "    fc_init = tf.uniform_unit_scaling_initializer(factor=1.0)\n",
    "    with tf.variable_scope('fc', initializer=fc_init):   \n",
    "        rnn_outputs_2d = tf.reshape(rnn_outputs, [-1, hps.num_lstm_nodes[-1]])\n",
    "        fc1 = tf.layers.dense(rnn_outputs_2d, hps.num_fc_nodes, name='fc1')\n",
    "        fc1_dropout = tf.nn.dropout(fc1, keep_prob)\n",
    "        fc1_dropout = tf.nn.relu(fc1_dropout)\n",
    "        logits = tf.layers.dense(fc1_dropout, vocab_size, name='logits')\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
